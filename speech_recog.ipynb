{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Super DTW speech Recognizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy.spatial.distance as dist\n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import split_on_silence\n",
    "\n",
    "# Audio process \n",
    "from scipy.io import wavfile\n",
    "import IPython.display as ipyd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "listenign\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write\n",
    "import wavio as wv\n",
    "  \n",
    "freq = 16000  \n",
    "duration = 7\n",
    "print('Escuchando...')\n",
    "recording = sd.rec(int(duration * freq), \n",
    "                   samplerate=freq, channels=1)  \n",
    "sd.wait()\n",
    "input_file2test = './audioInput.wav'\n",
    "wv.write(input_file2test, recording, freq, sampwidth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_file2test = 'src/coversor/files2conver/bot.wav' # Archivo a procesar\n",
    "# input_file2test = 'audios/tests/mike_test.wav' # MAd mike\n",
    "sound_file2test = AudioSegment.from_wav(input_file2test) # Aqui su archivo en WAV"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algoritmo DTW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dp(dist_mat):\n",
    "    N, M = dist_mat.shape\n",
    "    \n",
    "    # Initialize the cost matrix\n",
    "    cost_mat = np.zeros((N + 1, M + 1))\n",
    "    for i in range(1, N + 1):\n",
    "        cost_mat[i, 0] = np.inf\n",
    "    for i in range(1, M + 1):\n",
    "        cost_mat[0, i] = np.inf\n",
    "\n",
    "    # Fill the cost matrix while keeping traceback information\n",
    "    traceback_mat = np.zeros((N, M))\n",
    "    for i in range(N):\n",
    "        for j in range(M):\n",
    "            penalty = [\n",
    "                cost_mat[i, j],      # match (0)\n",
    "                cost_mat[i, j + 1],  # insertion (1)\n",
    "                cost_mat[i + 1, j]]  # deletion (2)\n",
    "            i_penalty = np.argmin(penalty)\n",
    "            cost_mat[i + 1, j + 1] = dist_mat[i, j] + penalty[i_penalty]\n",
    "            traceback_mat[i, j] = i_penalty\n",
    "\n",
    "    # Traceback from bottom right\n",
    "    i = N - 1\n",
    "    j = M - 1\n",
    "    path = [(i, j)]\n",
    "    while i > 0 or j > 0:\n",
    "        tb_type = traceback_mat[i, j]\n",
    "        if tb_type == 0:\n",
    "            # Match\n",
    "            i = i - 1\n",
    "            j = j - 1\n",
    "        elif tb_type == 1:\n",
    "            # Insertion\n",
    "            i = i - 1\n",
    "        elif tb_type == 2:\n",
    "            # Deletion\n",
    "            j = j - 1\n",
    "        path.append((i, j))\n",
    "\n",
    "    # Strip infinity edges from cost_mat before returning\n",
    "    cost_mat = cost_mat[1:, 1:]\n",
    "    return (path[::-1], cost_mat)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metodo para la obtencion de specs de los splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio a procesar\n",
    "# Primero extraemos el espectrograma \n",
    "# query_filename = \"src/coversor/convertedFiles/hello1.wav\" #Archivo a comparar\n",
    "\n",
    "def input_spec(query_fn):\n",
    "    f_s, x = wavfile.read(query_fn)\n",
    "    #------ the hop length\n",
    "    n_fft = int(0.025*f_s)      # 25 ms\n",
    "    hop_length = int(0.01*f_s)  # 10 ms\n",
    "    # Mel-scale spectrogram\n",
    "    mel_spec_x = librosa.feature.melspectrogram(\n",
    "    y=x/1.0, sr=f_s, n_mels=40,\n",
    "    n_fft=n_fft, hop_length=hop_length\n",
    "    )\n",
    "    log_mel_spec_x = np.log(mel_spec_x)\n",
    "    x_seq = log_mel_spec_x.T\n",
    "    # ipyd.Audio(rate=f_s, data=x)\n",
    "    return f_s, x, n_fft ,x_seq, hop_length"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### División de Audio original de entrada en segmentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exportando:  splits/chunk0.wav\n",
      "Exportando:  splits/chunk1.wav\n",
      "Exportando:  splits/chunk2.wav\n",
      "Exportando:  splits/chunk3.wav\n",
      "Exportando:  splits/chunk4.wav\n"
     ]
    }
   ],
   "source": [
    "audio_chunks = split_on_silence(sound_file2test, min_silence_len=200, silence_thresh=-30)\n",
    "# Los dividimos en segmentos en WAV -> mono canal y 16 bits de rate \n",
    "# print('The lem: ',len(audio_chunks), type(audio_chunks))\n",
    "for i, chunk in enumerate(audio_chunks):\n",
    "   sound = chunk\n",
    "   out_file = \"splits/chunk{0}.wav\".format(i)\n",
    "   # Here concert the audio to mono.\n",
    "   # sound = AudioSegment.from_mp3(source)  # load source\n",
    "   print(\"Exportando: \", out_file)\n",
    "   sound = sound.set_channels(1)  # mono   \n",
    "   sound = sound.set_frame_rate(16000)  # 16000Hz\n",
    "   # print(f'The audio segment channel: {sound.channels}')\n",
    "   sound.export(out_file, format=\"wav\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_folder = 'templates/audios'\n",
    "# src\\coversor\\convertedFiles"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lectura unica de templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_files = os.listdir(audio_folder)  # El escaneador de archivos\n",
    "\n",
    "data_per_templates = np.array([], dtype=object)\n",
    "for neighbour_fn in audio_files:\n",
    "    composePath = audio_folder + '/' + neighbour_fn\n",
    "    f_s, y = wavfile.read(composePath)\n",
    "    n_fft = int(0.025*f_s)      # 25 ms\n",
    "    hop_length = int(0.01*f_s)  # 10 ms\n",
    "    \n",
    "    mel_spec_y = librosa.feature.melspectrogram(\n",
    "        y=y/1.0, sr=f_s, n_mels=40,\n",
    "        n_fft=n_fft, hop_length=hop_length\n",
    "    )\n",
    "    log_mel_spec_y = np.log(mel_spec_y)\n",
    "    y_seq = log_mel_spec_y.T\n",
    "    \n",
    "    separator = '.'\n",
    "    word_label = neighbour_fn.split(separator, 1)[0]\n",
    "\n",
    "    data_per_templates = np.append(\n",
    "        data_per_templates, {\"palabra_t\": word_label, \"datos_spec\": y_seq})  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_per_templates"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparacion por DTW de split[i] ~= templates[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "splited_input = './splits'\n",
    "palabras_reconocidas = []\n",
    "audio_input_files = os.listdir(splited_input)\n",
    "for input_fn in audio_input_files:\n",
    "    path_x = splited_input +'/'+ input_fn\n",
    "    # sound_file = AudioSegment.from_wav(path_x) # Aqui su archivo en WAV\n",
    "    f_s_x, x, n_fft ,x_seq, hop_length = input_spec(path_x) # Extraendo el espec del audio(palabra) a analizar\n",
    "\n",
    "    # Aqui comparamos uno por uno  \n",
    "    min_values = np.array([], dtype=object)\n",
    "    # for i, template in np.ndenumerate(data_per_templates):\n",
    "    for template in data_per_templates:\n",
    "        y_data_spec = template.get('datos_spec')\n",
    "        dist_mat = dist.cdist(x_seq, y_data_spec, \"cosine\")\n",
    "        path, cost_mat = dp(dist_mat)\n",
    "        # print(\"Alignment cost: {:.6f}\".format(cost_mat[-1, -1]))\n",
    "        M = y_data_spec.shape[0]\n",
    "        N = x_seq.shape[0]\n",
    "        # print(f'Tamaños comparados: M->{M}; N->{N}')\n",
    "        # print(f'FileName: {neighbour_fn}')\n",
    "        # print(\n",
    "        # \"Normalized alignment cost: {:.8f}\".format(\n",
    "        # cost_mat[-1, -1]/(M + N))\n",
    "        # )\n",
    "        min_values = np.append(min_values,{\"palabra_id\":template.get('palabra_t') ,\"split_\":input_fn,\"costo\":cost_mat[-1, -1]/(M + N)})\n",
    "        # Here \n",
    "        minPricedItem = min(min_values, key=lambda x:x['costo'])\n",
    "\n",
    "    palabras_reconocidas.append(minPricedItem)     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'palabra_id': 'el', 'split_': 'chunk0.wav', 'costo': 0.010110092966510432},\n",
       " {'palabra_id': '7', 'split_': 'chunk1.wav', 'costo': 0.010236806256244384},\n",
       " {'palabra_id': 'el', 'split_': 'chunk2.wav', 'costo': 0.00893407324268928},\n",
       " {'palabra_id': 'aula', 'split_': 'chunk3.wav', 'costo': 0.008161790319128863},\n",
       " {'palabra_id': '7', 'split_': 'chunk4.wav', 'costo': 0.011840953090360777}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palabras_reconocidas\n",
    "# len(palabras_reconocidas)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8ae40dff0bf425ae7958368565db7ea993427bd043b66a59ca7823c0e984da74"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
